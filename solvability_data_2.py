import torch
import solvability_algorithm as alg
import solvability_algorithm_2 as alg2
from train_GAN_4_control import *


def create_data(test=False):
    # noise settings
    manualSeed = np.random.randint(1, 10000)
    random.seed(manualSeed)
    torch.manual_seed(manualSeed)


    #make generator and load learned weights
    gen = generator(100,3844)
    #gen.load_state_dict(torch.load('generator_weights_epoch_9.pth'))
    gen.eval()

    solvable_list = []
    not_solvable_list = []

    #training data for classifier are levels generated by generator at different moments in the training procces
    #this means that classifier is trained on all sort of proto-levels (levels produced by lowly trained generator)
    j = 0
    if test:
        limit = 5000
    else:
        limit = 5000
    while len(solvable_list) < limit or len(not_solvable_list) < limit:
    #while len(not_solvable_list) < 10000:
    #for j in range(0, 3800, 50):
        gen.load_state_dict(torch.load('control_batches/control_weights_control_batches_' + str(j) + '.pth'))
        for i in range(4):
            noise = torch.rand(40, 100)
            samples = gen(noise)
            batch_size = list(samples.size())[0]
            i = 0
            while i < batch_size:
                if alg.solvable(samples[i, :]):
                    if len(solvable_list) < limit:
                        trainingselement = (samples[i, :].tolist())
                        #trainingselement.append(1.0)
                        trainingselement += alg2.solvable(trainingselement)
                        solvable_list.append(trainingselement)
                elif len(not_solvable_list) < limit:
                    trainingselement = (samples[i, :].tolist())
                    #trainingselement.append(0.0)
                    trainingselement += alg2.solvable(trainingselement)
                    not_solvable_list.append(trainingselement)
                i += 1
        j = (j + 50) % 3800
        print("aantal solv: ", len(solvable_list))
        print("aantal nie solv; ", len(not_solvable_list))
        print("j ", j)
    """print("tweede deel...")
    while len(solvable_list) < 10000 or len(not_solvable_list) < 10000:
        noise = torch.rand(40, 100)
        samples = gen(noise)
        batch_size = list(samples.size())[0]
        i = 0
        while i < batch_size:
            if alg.solvable(samples[i, :]):
                if len(solvable_list) < 10000:
                    solvable_list.append(samples[i, :].tolist().append(1))
            elif len(not_solvable_list) < 10000:
                not_solvable_list.append(samples[i, :].tolist().append(0))
            i += 1"""

    data = solvable_list + not_solvable_list


    #check if how many solvable and not solvable training levels there are
    print("number of solvable training levels: ", len(solvable_list))
    print("number of not solvable training levels: ", len(not_solvable_list))


    # save the trainingslevels
    narr = np.asarray(data)
    # sla narr als csv op
    #np.savetxt("trainingsdata2_classifier.csv",
    #           narr,
    #           delimiter=", ",
    #           fmt='% s')
    np.savetxt("data_classifier_seth.csv",
               narr,
               delimiter=", ",
               fmt='% s')

if __name__=='__main__':
    create_data()